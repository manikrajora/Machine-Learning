{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy.random as rn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy import optimize\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn import neural_network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import *\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import keras\n",
    "from keras import losses\n",
    "from functools import partial\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86693964]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('leaf.csv', header=None)\n",
    "data.drop([1],inplace=True,axis=1)\n",
    "X = data.values[:,1:]\n",
    "Y_first = data.values[:,0]\n",
    "Y = []\n",
    "out = np.zeros(shape=[36])\n",
    "for i in range(np.shape(Y_first)[0]):\n",
    "    out[int(Y_first[i])-1]=1\n",
    "    Y.append(out)\n",
    "    out = np.zeros(shape=[36])\n",
    "Y = np.array(Y)\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# X_scaled = min_max_scaler.fit_transform(X)\n",
    "# df_normalized = pd.DataFrame(X_scaled)\n",
    "\n",
    "r,c = np.shape(X)\n",
    "\n",
    "total_samples = list(np.arange(0,r,1))\n",
    "test_samples = random.sample(total_samples,int(np.round(len(total_samples)*0.2)))\n",
    "train_samples = list(set(total_samples) - set(test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "trainX = X[train_samples]\n",
    "trainX_scaled = (trainX-np.min(trainX))/(np.max(trainX)-np.min(trainX))\n",
    "trainY = Y[train_samples]\n",
    "trainY_comp = Y_first[train_samples]\n",
    "\n",
    "testX = X[test_samples]\n",
    "testX_scaled = (testX-np.min(testX))/(np.max(testX)-np.min(testX))\n",
    "testY = Y[test_samples]\n",
    "testY_comp = Y_first[test_samples]\n",
    "print(len(trainX[0]))\n",
    "print(len(trainY[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_objective(x):\n",
    "    num_inputs = 14\n",
    "    num_outputs = 36\n",
    "\n",
    "    hidden_layer_neurons = 15\n",
    "    weights_all = num_inputs*hidden_layer_neurons + hidden_layer_neurons*num_outputs\n",
    "    bias_all = hidden_layer_neurons+num_outputs\n",
    "    iw_size = num_inputs*hidden_layer_neurons\n",
    "    nn_weights = x[:weights_all]\n",
    "    bias_all = x[weights_all:]\n",
    "    iw = nn_weights[0:iw_size]\n",
    "    ow = nn_weights[iw_size:]\n",
    "    b1 = bias_all[:hidden_layer_neurons]\n",
    "    b2 = bias_all[hidden_layer_neurons:]\n",
    "    w1 = np.reshape(iw,(num_inputs, hidden_layer_neurons))\n",
    "    w2 = np.reshape(ow,(hidden_layer_neurons, num_outputs))\n",
    "    l1 = np.maximum(np.dot(trainX, w1)+b1, 0)\n",
    "    x_i = np.dot(l1, w2)+b2\n",
    "    l2 = np.array(np.exp(x_i)/ np.exp(x_i).sum(axis=1)[:,None])  \n",
    "    l2_act = np.argmax(l2,axis=1)+1\n",
    "    output = np.clip(l2, 1e-15, 1. - 1e-15)\n",
    "    er= -np.sum(trainY * np.log(l2))\n",
    "    return er\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hillclimb(x,step_size,move_operator,objective_function,max_evaluations):\n",
    "    '''\n",
    "    hillclimb until either max_evaluations\n",
    "    is reached or we are at a local optima\n",
    "    '''\n",
    "    best=np.copy(x)\n",
    "    best_score=objective_function(best[0])\n",
    "    \n",
    "    num_evaluations=1\n",
    "    \n",
    "    while num_evaluations < max_evaluations:\n",
    "        # examine moves around our current position\n",
    "        move_made=False\n",
    "        for next in move_operator(best,step_size):\n",
    "            if num_evaluations >= max_evaluations:\n",
    "                break\n",
    "            \n",
    "            # see if this move is better than the current\n",
    "            next_score=objective_function(next)\n",
    "            num_evaluations+=1\n",
    "            if next_score < best_score:\n",
    "                best=np.array([next])\n",
    "                best_score=next_score\n",
    "                move_made=True\n",
    "                break # depth first search\n",
    "            \n",
    "        if not move_made:\n",
    "            break # we couldn't find a better move \n",
    "                     # (must be at a local maximum)\n",
    "    \n",
    "    return (num_evaluations,best_score,best)\n",
    "\n",
    "def move(x,step_size):\n",
    "    b = np.transpose(np.concatenate((x-0.5,x,x+0.5)))\n",
    "    print(b)\n",
    "    st\n",
    "    return b_i   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 14\n",
    "num_outputs = 36\n",
    "\n",
    "hidden_layer_neurons = 15\n",
    "\n",
    "weights_all = num_inputs*hidden_layer_neurons + hidden_layer_neurons*num_outputs\n",
    "bias_all = hidden_layer_neurons+num_outputs\n",
    "\n",
    "tw = weights_all+bias_all \n",
    "w0 = 2*np.random.random((1,tw))-2\n",
    "\n",
    "num_evaluations,best_score,best = hillclimb(w0,0.5,move,nn_objective,100000)\n",
    "\n",
    "print([num_evaluations,best_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 28.  14.  35.  23.  34.  31.  22.  15.  35.  11.  35.  11.  25.  13.  26.\n",
      "  10.  26.  26.  31.  15.  26.  14.  36.  26.  32.  12.   9.   7.  27.  29.\n",
      "  12.  12.  11.  23.   2.  33.   9.   8.   5.   8.   9.   2.   5.   1.  23.\n",
      "  12.  14.  28.  29.  25.  33.   9.  12.   1.  28.  35.  11.   2.   4.  15.\n",
      "  11.  30.  22.   6.  24.   2.  25.   4.]\n",
      "[35 35 12  3 34 31 22 10 35 11 14 11  9 24 24 10 24 29 31 36 24 35 36 24 32\n",
      " 22  9  7 27 29  5 35 11 11 32 13 30  8 12  8  3 22  5 29  3 12 28 35 29  9\n",
      " 27  9 12 27 35 35 11 28  3 15 11 30 22 11 13 32  9  9]\n",
      "0.588235294118\n"
     ]
    }
   ],
   "source": [
    "x = state[0]\n",
    "\n",
    "def nn_objective_test(x):\n",
    "    num_inputs = 14\n",
    "    num_outputs = 36\n",
    "\n",
    "    hidden_layer_neurons = 15\n",
    "    \n",
    "    weights_all = num_inputs*hidden_layer_neurons + hidden_layer_neurons*num_outputs\n",
    "    bias_all = hidden_layer_neurons+num_outputs\n",
    "    iw_size = num_inputs*hidden_layer_neurons\n",
    "    nn_weights = x[:weights_all]\n",
    "    bias_all = x[weights_all:]\n",
    "    iw = nn_weights[0:iw_size]\n",
    "    ow = nn_weights[iw_size:]\n",
    "    b1 = bias_all[:hidden_layer_neurons]\n",
    "    b2 = bias_all[hidden_layer_neurons:]\n",
    "\n",
    "    w1 = np.reshape(iw,(num_inputs, hidden_layer_neurons))\n",
    "    w2 = np.reshape(ow,(hidden_layer_neurons, num_outputs))\n",
    "    l1 = np.maximum(np.dot(testX, w1)+b1, 0)\n",
    "    x_i = np.dot(l1, w2)+b2\n",
    "    l2 = np.array(np.exp(x_i)/ np.exp(x_i).sum(axis=1)[:,None])  \n",
    "    print(np.sum(l2,axis=1))\n",
    "#     l2 = np.exp(x_i) / (1 + np.exp(x_i))\n",
    "    l2_act = np.argmax(l2,axis=1)+1\n",
    "    predict_out = l2_act\n",
    "    predict_out = predict_out.flatten()\n",
    "    acc = 1-accuracy_score(testY_comp,predict_out)\n",
    "    print(testY_comp)\n",
    "    print(predict_out)\n",
    "    return acc\n",
    "\n",
    "test_miss = nn_objective_test(x)\n",
    "print(test_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  1.   1.5]\n",
      " [ 1.5  2.   2.5]\n",
      " [ 2.5  3.   3.5]]\n",
      "[(0.5, 1.5, 2.5), (0.5, 1.5, 3.0), (0.5, 1.5, 3.5), (0.5, 2.0, 2.5), (0.5, 2.0, 3.0), (0.5, 2.0, 3.5), (0.5, 2.5, 2.5), (0.5, 2.5, 3.0), (0.5, 2.5, 3.5), (1.0, 1.5, 2.5), (1.0, 1.5, 3.0), (1.0, 1.5, 3.5), (1.0, 2.0, 2.5), (1.0, 2.0, 3.0), (1.0, 2.0, 3.5), (1.0, 2.5, 2.5), (1.0, 2.5, 3.0), (1.0, 2.5, 3.5), (1.5, 1.5, 2.5), (1.5, 1.5, 3.0), (1.5, 1.5, 3.5), (1.5, 2.0, 2.5), (1.5, 2.0, 3.0), (1.5, 2.0, 3.5), (1.5, 2.5, 2.5), (1.5, 2.5, 3.0), (1.5, 2.5, 3.5)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
