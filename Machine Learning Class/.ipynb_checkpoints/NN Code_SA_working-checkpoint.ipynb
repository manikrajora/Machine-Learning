{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy import optimize\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn import neural_network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import *\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras\n",
    "from keras import losses\n",
    "\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('leaf.csv', header=None)\n",
    "data.drop([1],inplace=True,axis=1)\n",
    "X = data.values[:,1:]\n",
    "Y_first = data.values[:,0]\n",
    "Y = []\n",
    "out = np.zeros(shape=[36])\n",
    "for i in range(np.shape(Y_first)[0]):\n",
    "    out[int(Y_first[i])-1]=1\n",
    "    Y.append(out)\n",
    "    out = np.zeros(shape=[36])\n",
    "Y = np.array(Y)\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# X_scaled = min_max_scaler.fit_transform(X)\n",
    "# df_normalized = pd.DataFrame(X_scaled)\n",
    "\n",
    "r,c = np.shape(X)\n",
    "\n",
    "total_samples = list(np.arange(0,r,1))\n",
    "test_samples = random.sample(total_samples,int(np.round(len(total_samples)*0.2)))\n",
    "train_samples = list(set(total_samples) - set(test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "trainX = X[train_samples]\n",
    "trainX_scaled = (trainX-np.min(trainX))/(np.max(trainX)-np.min(trainX))\n",
    "trainY = Y[train_samples]\n",
    "trainY_comp = Y_first[train_samples]\n",
    "\n",
    "testX = X[test_samples]\n",
    "testX_scaled = (testX-np.min(testX))/(np.max(testX)-np.min(testX))\n",
    "testY = Y[test_samples]\n",
    "testY_comp = Y_first[test_samples]\n",
    "print(len(trainX[0]))\n",
    "print(len(trainY[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(true_label, predicted, eps=1e-15):\n",
    "  p = np.clip(predicted, eps, 1 - eps)\n",
    "  if true_label == 1:\n",
    "    return -np.log(p)\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de(fobj, bounds=[-5,5], mut=0.8, crossp=0.7, popsize=50, its=1000):\n",
    "    dimensions = len(bounds)\n",
    "    pop = np.random.rand(popsize, dimensions)\n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    diff = np.fabs(min_b - max_b)\n",
    "    pop_denorm = min_b + pop * diff\n",
    "    fitness = np.asarray([fobj(ind) for ind in pop_denorm])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = pop_denorm[best_idx]\n",
    "    for i in range(its):\n",
    "        if i == 0:\n",
    "            best_all = best\n",
    "            fitness_best_all = fitness[best_idx]\n",
    "        for j in range(popsize):\n",
    "            idxs = [idx for idx in range(popsize) if idx != j]\n",
    "            a, b, c = pop[np.random.choice(idxs, 3, replace = False)]\n",
    "            mutant = np.clip(a + mut * (b - c), 0, 1)\n",
    "            cross_points = np.random.rand(dimensions) < crossp\n",
    "            if not np.any(cross_points):\n",
    "                cross_points[np.random.randint(0, dimensions)] = True\n",
    "            trial = np.where(cross_points, mutant, pop[j])\n",
    "            trial_denorm = min_b + trial * diff\n",
    "            f = fobj(trial_denorm)\n",
    "            if f < fitness[j]:\n",
    "                fitness[j] = f\n",
    "                pop[j] = trial\n",
    "                if f < fitness[best_idx]:\n",
    "                    best_idx = j\n",
    "                    best = trial_denorm\n",
    "                if fitness[best_idx]<fitness_best_all:\n",
    "                    best_all = best\n",
    "                    fitness_best_all = fitness[best_idx]\n",
    "    return best_all, fitness_best_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_objective(x):\n",
    "    num_inputs = 14\n",
    "    num_outputs = 36\n",
    "\n",
    "    hidden_layer_neurons = 15\n",
    "    \n",
    "    weights_all = num_inputs*hidden_layer_neurons + hidden_layer_neurons*num_outputs\n",
    "    bias_all = hidden_layer_neurons+num_outputs\n",
    "    iw_size = num_inputs*hidden_layer_neurons\n",
    "    nn_weights = x[:weights_all]\n",
    "    bias_all = x[weights_all:]\n",
    "    iw = nn_weights[0:iw_size]\n",
    "    ow = nn_weights[iw_size:]\n",
    "    b1 = bias_all[:hidden_layer_neurons]\n",
    "    b2 = bias_all[hidden_layer_neurons:]\n",
    "    w1 = np.reshape(iw,(num_inputs, hidden_layer_neurons))\n",
    "    w2 = np.reshape(ow,(hidden_layer_neurons, num_outputs))\n",
    "#     l1 = 1/(1+np.exp(-(np.dot(trainX,w1)+b1)))\n",
    "    l1 = np.maximum(np.dot(trainX, w1)+b1, 0)\n",
    "    x_i = np.dot(l1, w2)+b2\n",
    "    l2 = np.array(np.exp(x_i)/ np.exp(x_i).sum(axis=1)[:,None])  \n",
    "#     l2 = np.exp(x_i) / (1 + np.exp(x_i))\n",
    "    l2_act = np.argmax(l2,axis=1)+1\n",
    "#     predict_out = l2_act.flatten()\n",
    "#     acc = 1-accuracy_score(trainY_comp,predict_out)\n",
    "#     er_t = []\n",
    "#     er_i = 0\n",
    "#     for i in range(np.shape(trainY)[0]):\n",
    "#         for j in range(np.shape(trainY)[1]):\n",
    "#             er_i += logloss(np.array(trainY[i,j]),np.array(l2[i,j]))\n",
    "#         #er_t.append(er_i)\n",
    "#     er = np.mean(er_i)\n",
    "    output = np.clip(l2, 1e-15, 1. - 1e-15)\n",
    "    er= -np.sum(trainY * np.log(l2))\n",
    "    return er\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-901e5b74bd03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnn_keras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mweights_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhidden_layer_neurons\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhidden_layer_neurons\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbias_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_layer_neurons\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res1' is not defined"
     ]
    }
   ],
   "source": [
    "x = res1[0]\n",
    "\n",
    "def nn_keras(x):\n",
    "    weights_all = num_inputs*hidden_layer_neurons + hidden_layer_neurons*num_outputs\n",
    "    bias_all = hidden_layer_neurons+num_outputs\n",
    "    iw_size = num_inputs*hidden_layer_neurons\n",
    "    nn_weights = x[:weights_all]\n",
    "    bias_all = x[weights_all:]\n",
    "    iw = nn_weights[0:iw_size]\n",
    "    ow = nn_weights[iw_size:]\n",
    "    b1 = bias_all[:hidden_layer_neurons]\n",
    "    b2 = bias_all[hidden_layer_neurons:]\n",
    "    w1 = np.reshape(iw,(num_inputs, hidden_layer_neurons))\n",
    "    w2 = np.reshape(ow,(hidden_layer_neurons, num_outputs))\n",
    "\n",
    "    w1_all = []\n",
    "    w1_all.append(w1)\n",
    "    w1_all.append(b1)\n",
    "\n",
    "    w2_all = []\n",
    "    w2_all.append(w2)\n",
    "    w2_all.append(b2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(36, kernel_initializer='normal', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.layers[0].set_weights(w1_all)\n",
    "    model.layers[1].set_weights(w2_all)\n",
    "    out = model.predict(trainX)\n",
    "    output = np.clip(out, 1e-15, 1. - 1e-15)\n",
    "    er= -np.sum(trainY * np.log(output))\n",
    "    predict_out = np.argmax(out,axis=1)+1\n",
    "#     acc = 1-accuracy_score(testY_comp,predict_out)\n",
    "#     print(acc)\n",
    "    return er\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "689.672207195\n",
      "605.690309395\n",
      "642.381393448\n",
      "762.933092751\n",
      "725.983424158\n",
      "613.729556295\n",
      "836.948343809\n",
      "766.602242576\n",
      "726.631517427\n",
      "1\n",
      "708.094496558\n",
      "737.605380423\n",
      "794.660677918\n",
      "533.532597021\n",
      "584.800445066\n",
      "669.83598856\n",
      "647.548197081\n",
      "503.300281451\n",
      "532.769924051\n",
      "2\n",
      "850.563527313\n",
      "863.844695924\n",
      "869.01553492\n",
      "802.728176939\n",
      "801.925007828\n",
      "863.839203767\n",
      "700.661418079\n",
      "741.301042822\n",
      "838.664312619\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 14\n",
    "num_outputs = 36\n",
    "\n",
    "hidden_layer_neurons = 15\n",
    "\n",
    "weights_all = num_inputs*hidden_layer_neurons + hidden_layer_neurons*num_outputs\n",
    "bias_all = hidden_layer_neurons+num_outputs\n",
    "\n",
    "tw = weights_all+bias_all \n",
    "w0 = 2*np.random.random((1,tw))-2\n",
    "\n",
    "b = [(-1,1)]\n",
    "for i in range(len(w0[0])-1):\n",
    "    b.append((-1,1))\n",
    "\n",
    "mut_all = np.array([0.0,0.25,0.5])\n",
    "crossp_all = np.array([0.4,0.6,0.8])\n",
    "popsize_all = np.array([50,100,200])\n",
    "r_all = []\n",
    "for i in range(len(mut_all)):\n",
    "    print(i)\n",
    "    for j in range(len(crossp_all)):\n",
    "        for k in range(len(popsize_all)):\n",
    "            res1 = list(de(nn_objective,b,mut=mut_all[i], crossp=crossp_all[j], popsize=popsize_all[k], its=500))\n",
    "            r_all.append(np.array([mut_all[i],crossp_all[j],popsize_all[k],res1[1]]))\n",
    "            print(res1[1])\n",
    "#res = optimize.basinhopping(nn_objective, w0[0], niter=1000,disp=True)\n",
    "# res1 = list(de(nn_objective,b,mut=0.0, crossp=0.9, popsize=50, its=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 4)\n",
      "[  2.50000000e-01   8.00000000e-01   1.00000000e+02   5.03300281e+02]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(r_all))\n",
    "all_vals = np.reshape(r_all,(27,4))\n",
    "b_idx = np.argmin(all_vals[:,-1])\n",
    "b_vals = all_vals[16,:]\n",
    "print(b_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1_f = list(de(nn_objective,b,mut=b_vals[0], crossp=b_vals[1], popsize=int(b_vals[2]), its=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 26.  35.  29.  13.  15.  11.  13.  14.  27.   7.   8.  35.  11.   1.   7.\n",
      "   8.  10.  25.  34.  13.   2.   6.   8.   2.  13.   7.  24.  26.  12.  34.\n",
      "  13.  36.  24.  26.   6.  12.   1.  22.  29.  27.   6.  27.   7.  24.  26.\n",
      "   7.  22.  10.  13.  12.  29.  15.  14.  13.   1.  11.  26.  10.  30.   5.\n",
      "  23.  36.  32.  11.  32.   9.   5.   6.]\n",
      "[27 28 29 33 15 11 33 28 33  7  8 22 11  1  5  8 15 25 34 33  2  6  8 32 33\n",
      "  5 27 30 35 34 33 36  4 24 11 12  1 22 29 27 23 27  7 24  4  5  5 30 33 12\n",
      " 29 15 28 33  1 11 32  9 10  5 23 36 32 11 32  3  5 23]\n",
      "0.485294117647\n"
     ]
    }
   ],
   "source": [
    "x = res1_f[0]\n",
    "\n",
    "def nn_objective_test(x):\n",
    "    num_inputs = 14\n",
    "    num_outputs = 36\n",
    "\n",
    "    hidden_layer_neurons = 15\n",
    "    \n",
    "    weights_all = num_inputs*hidden_layer_neurons + hidden_layer_neurons*num_outputs\n",
    "    bias_all = hidden_layer_neurons+num_outputs\n",
    "    iw_size = num_inputs*hidden_layer_neurons\n",
    "    nn_weights = x[:weights_all]\n",
    "    bias_all = x[weights_all:]\n",
    "    iw = nn_weights[0:iw_size]\n",
    "    ow = nn_weights[iw_size:]\n",
    "    b1 = bias_all[:hidden_layer_neurons]\n",
    "    b2 = bias_all[hidden_layer_neurons:]\n",
    "\n",
    "    w1 = np.reshape(iw,(num_inputs, hidden_layer_neurons))\n",
    "    w2 = np.reshape(ow,(hidden_layer_neurons, num_outputs))\n",
    "    l1 = np.maximum(np.dot(testX, w1)+b1, 0)\n",
    "    x_i = np.dot(l1, w2)+b2\n",
    "    l2 = np.array(np.exp(x_i)/ np.exp(x_i).sum(axis=1)[:,None])  \n",
    "    print(np.sum(l2,axis=1))\n",
    "#     l2 = np.exp(x_i) / (1 + np.exp(x_i))\n",
    "    l2_act = np.argmax(l2,axis=1)+1\n",
    "    predict_out = l2_act\n",
    "    predict_out = predict_out.flatten()\n",
    "    acc = 1-accuracy_score(testY_comp,predict_out)\n",
    "    print(testY_comp)\n",
    "    print(predict_out)\n",
    "    return acc\n",
    "\n",
    "test_miss = nn_objective_test(x)\n",
    "print(test_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_weights\n",
      "optimizer_weights\n",
      "['dense_1', 'dense_2']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "file_name = \"weights.best_leaf.hdf5\"\n",
    "data = h5py.File(file_name,'r')\n",
    "\n",
    "for key in data.keys():\n",
    "    print(key) #Names of the groups in HDF5 file.\n",
    "\n",
    "# group = data['model_weights']\n",
    "# data = group['model_weights']\n",
    "\n",
    "d = list(data['model_weights'])\n",
    "print(d[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"weights.best_leaf.hdf5\")\n",
    "print(model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(\"weights.best_leaf.hdf5\", 'r')\n",
    "print(list(f.keys()))\n",
    "#will get a list of layer names which you can use as index\n",
    "d = f['model_weights']['dense_1']\n",
    "print(list(d.get('dense_1').keys()))\n",
    "d.get('dense_1').get('bias:0')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
